# Recovery Guarantees and Durability Semantics

This document describes Manifold's crash recovery guarantees, durability semantics, and the behavior of the Write-Ahead Log (WAL) system.

## Table of Contents

- [Overview](#overview)
- [Durability Guarantees](#durability-guarantees)
- [Recovery Behavior](#recovery-behavior)
- [WAL Architecture](#wal-architecture)
- [Failure Scenarios](#failure-scenarios)
- [Performance Considerations](#performance-considerations)
- [Best Practices](#best-practices)

---

## Overview

Manifold provides **full ACID guarantees** with crash recovery powered by a Write-Ahead Log (WAL). When enabled (default), the WAL ensures that committed transactions survive crashes, power failures, and other unexpected shutdowns.

### Key Guarantees

- ‚úÖ **Atomicity**: Transactions are all-or-nothing. After a crash, either all changes from a committed transaction are present, or none are.
- ‚úÖ **Consistency**: Database remains in a valid state after recovery. No partial writes or corrupted data structures.
- ‚úÖ **Isolation**: Recovered transactions maintain their isolation properties. No inter-transaction corruption.
- ‚úÖ **Durability**: Once `commit()` returns successfully, data survives crashes (with `Durability::Immediate`).

---

## Durability Guarantees

### With WAL Enabled (Default)

When WAL is enabled (the default configuration), Manifold provides the following guarantees:

```rust
use manifold::column_family::ColumnFamilyDatabase;

// WAL is enabled by default
let db = ColumnFamilyDatabase::builder().open("data.manifold")?;
let cf = db.column_family_or_create("users")?;

let txn = cf.begin_write()?;
{
    let mut table = txn.open_table(TABLE)?;
    table.insert(&key, &value)?;
}
txn.commit()?; // ‚Üê Data is durable after this returns
```

**Guarantees after `commit()` returns:**

1. **Transaction is durable**: Data will survive crashes, power failures, and kernel panics
2. **Recovery is automatic**: On next database open, WAL replay restores all committed transactions
3. **Fast commits**: WAL commits are ~200-250x faster than full B-tree sync (0.5ms vs ~5ms)

### Durability Modes

Manifold supports two durability modes via `Durability` enum:

#### `Durability::Immediate` (Default)

- Transaction is written to WAL and fsync'd before `commit()` returns
- **Guarantee**: Data survives any crash after `commit()` succeeds
- **Use case**: Critical data that must not be lost (user data, financial records, etc.)

```rust
// Immediate durability (default)
txn.set_durability(Durability::Immediate)?;
txn.commit()?; // Data is durable NOW
```

#### `Durability::None`

- Transaction is written to WAL but NOT immediately fsync'd
- **Guarantee**: Data survives clean shutdown, but may be lost on crash
- **Use case**: High-throughput scenarios where some data loss is acceptable (logs, caches, analytics)

```rust
// No durability (faster, but data may be lost on crash)
txn.set_durability(Durability::None)?;
txn.commit()?; // Fast return, but data may be lost on crash
```

### Without WAL

If WAL is explicitly disabled:

```rust
let db = ColumnFamilyDatabase::builder()
    .disable_wal()
    .open("data.manifold")?;
```

**Guarantees:**
- Commits are slower (~5ms vs ~0.5ms)
- Data is durable immediately (full B-tree sync on every commit)
- No WAL replay needed on recovery
- **Use case**: Scenarios where WAL overhead is unacceptable, or write volume is very low

---

## Recovery Behavior

### Automatic WAL Replay

When a database with WAL is opened, Manifold automatically:

1. **Detects uncommitted WAL entries** by comparing WAL sequence numbers with database state
2. **Replays committed transactions** from the WAL in order
3. **Reconstructs database state** by applying WAL entries to the B-tree
4. **Validates data integrity** via CRC32 checksums on WAL entries
5. **Truncates the WAL** after successful replay

This process is **fully automatic** and requires no user intervention:

```rust
// After a crash, simply reopen the database
let db = ColumnFamilyDatabase::builder().open("data.manifold")?;
// ‚Üë WAL replay happens here automatically
```

### Recovery Timeline

```
Time:     t0          t1          t2          t3          t4
          ‚îÇ           ‚îÇ           ‚îÇ           ‚îÇ           ‚îÇ
Action:   Begin       Insert      Commit      Crash!      Reopen
          Write       Data        (fsync)                 Database
          ‚îÇ           ‚îÇ           ‚îÇ           ‚îÇ           ‚îÇ
          ‚îÇ           ‚îÇ           ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>‚îÇ
          ‚îÇ           ‚îÇ           ‚îÇ                       ‚îÇ
WAL:      ‚îÇ           ‚îÇ           Entry                   Replay
          ‚îÇ           ‚îÇ           Written                 Entry
          ‚îÇ           ‚îÇ           & Synced                ‚îÇ
          ‚îÇ           ‚îÇ           ‚îÇ                       ‚îÇ
Result:   ‚îÇ           ‚îÇ           ‚îÇ           ‚îÇ           Data
          ‚îÇ           ‚îÇ           ‚îÇ           ‚îÇ           Recovered!
```

### What Gets Recovered

‚úÖ **Recovered:**
- All transactions that called `commit()` successfully
- Both user data and system metadata (table definitions, allocator state)
- All column families and their independent transaction histories

‚ùå **NOT Recovered:**
- Transactions that did not call `commit()`
- Transactions that crashed during `commit()` before WAL entry was written
- Transactions with `Durability::None` if crash occurred before background checkpoint

### Recovery Performance

- **Fast recovery**: ~300K WAL entries/second
- **Minimal downtime**: Recovery completes before database is ready for use
- **No user intervention**: Fully automatic on database open

---

## WAL Architecture

### WAL Entry Structure

Each WAL entry contains:

```rust
pub struct WALEntry {
    sequence: u64,              // Monotonic sequence number
    cf_name: String,            // Column family name
    transaction_id: u64,        // Transaction ID
    payload: WALTransactionPayload,
}

pub struct WALTransactionPayload {
    user_root: Option<(PageNumber, Checksum, u64)>,
    system_root: Option<(PageNumber, Checksum, u64)>,
    freed_pages: Vec<PageNumber>,
    allocated_pages: Vec<PageNumber>,
    durability: Durability,
}
```

### CRC Protection

- Every WAL entry has a **CRC32 checksum**
- Corruption is detected during replay
- Replay stops at first corrupted entry (all-or-nothing)
- Prevents silent data corruption

### Checkpointing

Background checkpointing applies WAL entries to the main database:

- **Triggered by**: Time interval (default 60s) OR WAL size threshold (default 64MB)
- **Process**:
  1. Read pending WAL entries
  2. Apply to main database B-tree
  3. Fsync database
  4. Truncate WAL
- **Result**: Bounded WAL size, improved recovery speed

---

## Failure Scenarios

### Scenario 1: Crash After Commit

```rust
txn.commit()?; // ‚Üê Returns successfully
// ... CRASH HERE ...
```

**Result**: ‚úÖ **Data is recovered**
- WAL entry was written and fsync'd
- Recovery replays the transaction
- All data is present after reopen

### Scenario 2: Crash Before Commit

```rust
let mut table = txn.open_table(TABLE)?;
table.insert(&key, &value)?;
// ... CRASH HERE (before commit) ...
```

**Result**: ‚ùå **Data is NOT recovered**
- Transaction never committed
- WAL entry was never written
- Database reverts to state before transaction
- **This is correct behavior** (atomicity guarantee)

### Scenario 3: Crash During Commit

```rust
txn.commit()?; // ‚Üê Crash DURING this call
```

**Result**: Depends on timing
- If WAL entry written + fsync'd: ‚úÖ **Data recovered**
- If WAL entry not written: ‚ùå **Data lost** (as if commit never called)
- Either way: **No partial state** (atomicity preserved)

### Scenario 4: Power Failure

Same as crash scenarios above. Fsync guarantees persist to physical media.

### Scenario 5: Filesystem Corruption

WAL CRC checksums detect corruption:
- **Detected**: Recovery stops, database remains in last known good state
- **Error returned**: User can restore from backup
- **Recommendation**: Use journaling filesystems (ext4, XFS, APFS, NTFS)

### Scenario 6: Multi-Column Family Crash

```rust
// Write to CF1
cf1_txn.commit()?; // ‚Üê Committed
// Write to CF2
// ... CRASH before CF2 commit ...
```

**Result**: ‚úÖ **CF1 recovered, CF2 not recovered**
- Each column family has independent WAL entries
- Recovery is per-CF atomic
- No cross-CF corruption

---

## Performance Considerations

### Write Performance

| Configuration | Commit Latency | Throughput (8 threads) | Crash Safety |
|--------------|----------------|------------------------|--------------|
| WAL (Immediate) | ~0.5ms | ~250K ops/sec | ‚úÖ Full |
| WAL (None) | ~0.1ms | ~450K ops/sec | ‚ö†Ô∏è  Eventual |
| No WAL | ~5ms | ~50K ops/sec | ‚úÖ Immediate |

### Recovery Performance

- **Small WAL** (<1000 entries): <10ms recovery time
- **Medium WAL** (10K entries): ~30ms recovery time
- **Large WAL** (100K entries): ~300ms recovery time

**Recommendation**: Enable checkpointing to keep WAL bounded

### Memory Usage

- WAL uses minimal memory (~1MB buffer)
- Recovery uses ~10MB for batch processing
- No impact on normal operation

---

## Best Practices

### For Production Systems

1. ‚úÖ **Enable WAL** (default):
   ```rust
   let db = ColumnFamilyDatabase::builder().open(path)?;
   ```

2. ‚úÖ **Use `Durability::Immediate`** for critical data:
   ```rust
   txn.set_durability(Durability::Immediate)?;
   ```

3. ‚úÖ **Regular backups**: WAL protects against crashes, not filesystem corruption or hardware failure

4. ‚úÖ **Monitor disk space**: Ensure adequate space for database + WAL growth

5. ‚úÖ **Use journaling filesystems**: ext4, XFS, APFS, NTFS provide additional protection

### For High-Throughput Systems

1. ‚ö° **Batch writes** in single transactions:
   ```rust
   let txn = cf.begin_write()?;
   for item in items {
       table.insert(&item.key, &item.value)?;
   }
   txn.commit()?; // One fsync for all items
   ```

2. ‚ö° **Consider `Durability::None`** for non-critical data:
   ```rust
   // Analytics, logs, caches
   txn.set_durability(Durability::None)?;
   ```

3. ‚ö° **Adjust checkpoint intervals** if needed:
   ```rust
   // Check WAL configuration options
   ```

### For Development/Testing

1. üß™ **Test crash scenarios** with the test harness:
   ```rust
   // See tests/crash_recovery_tests.rs for examples
   ```

2. üß™ **Verify recovery** in integration tests:
   ```rust
   // Write data, drop database, reopen, verify
   ```

3. üß™ **Monitor WAL size** during load testing

---

## Troubleshooting

### "WAL replay failed"

**Cause**: WAL file is corrupted or CRC mismatch

**Solutions**:
1. Check filesystem for errors (`fsck`, `chkdsk`)
2. Restore from backup if available
3. If no backup: database is in last checkpointed state (some recent data may be lost)

### Slow Recovery

**Cause**: Large WAL file (many uncommitted entries)

**Solutions**:
1. Enable or reduce checkpoint interval
2. Reduce checkpoint size threshold
3. This is a one-time cost on open

### Missing Data After Crash

**Cause**: Transaction was not committed, or used `Durability::None`

**Solutions**:
1. Verify `commit()` was called
2. Use `Durability::Immediate` for critical data
3. Implement retry logic for transient failures

---

## Recovery Guarantees Summary

| Scenario | Data Recovered? | Notes |
|----------|----------------|-------|
| Crash after `commit()` with `Durability::Immediate` | ‚úÖ Yes | Guaranteed |
| Crash after `commit()` with `Durability::None` | ‚ö†Ô∏è Maybe | Depends on checkpoint |
| Crash before `commit()` | ‚ùå No | Expected (atomicity) |
| Crash during `commit()` | ‚ö†Ô∏è Maybe | Depends on fsync completion |
| Power failure | ‚úÖ Same as crash | Fsync guarantees persist |
| Filesystem corruption | ‚ùå No | CRC detects, stops replay |
| Multi-CF crash | ‚úÖ Per-CF atomic | Independent recovery |

---

## References

- [WAL Design Document](wal_design.md) - Implementation details
- [Troubleshooting Guide](../TROUBLESHOOTING.md) - Common issues
- [Architecture Overview](design.md) - Overall system design
- [Crash Recovery Tests](../tests/crash_recovery_tests.rs) - Test harness examples

---

## Limitations

1. **No cross-transaction recovery**: If transaction A depends on transaction B, and B is lost, A may be invalid
2. **No cross-process coordination**: WAL does not protect against concurrent writers (use lock file)
3. **No replication**: WAL is local to the database file
4. **Storage requirements**: WAL requires additional disk space (bounded by checkpoint settings)

For multi-writer scenarios, distributed transactions, or replication, consider using Manifold as a component in a larger distributed system with appropriate coordination mechanisms.